{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    e = y - tx @ w\n",
    "    N = y.shape[0]\n",
    "    # ***************************************************\n",
    "    return (1/(2*N)) * e.T @ e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2694.483365887085"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([1, 2])\n",
    "compute_loss(y, tx, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    # ***************************************************\n",
    "    for i in range(losses.shape[0]):\n",
    "        for j in range(losses.shape[1]):\n",
    "            w = np.array([grid_w0[i], grid_w1[j]])\n",
    "            losses[i][j] = compute_loss(y, tx, w)\n",
    "    # ***************************************************\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=18.79354101952324, w0*=71.42857142857142, w1*=15.306122448979579, execution time=0.324 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=50)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-72.293922   -11.47971243]\n",
      "[26.706078    6.52028757]\n",
      "[-23.293922    -3.47971243]\n"
     ]
    }
   ],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    N = y.shape[0]\n",
    "    e = y - tx @ w\n",
    "    # ***************************************************\n",
    "    return (-1/N) * tx.T @ e\n",
    "\n",
    "print(compute_gradient(y, tx, np.array([1, 2])))\n",
    "print(compute_gradient(y, tx, np.array([100, 20])))\n",
    "print(compute_gradient(y, tx, np.array([50, 10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # compute gradient and loss\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        grad = compute_gradient(y, tx, w)\n",
    "        # ***************************************************\n",
    "        # update w by gradient\n",
    "        w = w - gamma * grad\n",
    "        # ***************************************************\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2792.2367127591674, w0=51.30574540147363, w1=9.435798704492301\n",
      "GD iter. 1/49: loss=265.30246210895996, w0=66.69746902191574, w1=12.266538315840002\n",
      "GD iter. 2/49: loss=37.87837955044107, w0=71.31498610804834, w1=13.115760199244328\n",
      "GD iter. 3/49: loss=17.41021212017447, w0=72.70024123388814, w1=13.37052676426563\n",
      "GD iter. 4/49: loss=15.568077051450452, w0=73.11581777164007, w1=13.446956733772023\n",
      "GD iter. 5/49: loss=15.402284895265302, w0=73.24049073296565, w1=13.469885724623941\n",
      "GD iter. 6/49: loss=15.387363601208634, w0=73.27789262136332, w1=13.476764421879516\n",
      "GD iter. 7/49: loss=15.38602068474353, w0=73.28911318788263, w1=13.478828031056189\n",
      "GD iter. 8/49: loss=15.385899822261674, w0=73.29247935783842, w1=13.47944711380919\n",
      "GD iter. 9/49: loss=15.385888944638305, w0=73.29348920882516, w1=13.47963283863509\n",
      "GD iter. 10/49: loss=15.385887965652199, w0=73.29379216412119, w1=13.479688556082861\n",
      "GD iter. 11/49: loss=15.38588787754345, w0=73.29388305071, w1=13.479705271317192\n",
      "GD iter. 12/49: loss=15.385887869613665, w0=73.29391031668663, w1=13.479710285887492\n",
      "GD iter. 13/49: loss=15.385887868899985, w0=73.29391849647962, w1=13.479711790258582\n",
      "GD iter. 14/49: loss=15.385887868835756, w0=73.29392095041752, w1=13.479712241569908\n",
      "GD iter. 15/49: loss=15.385887868829968, w0=73.29392168659889, w1=13.479712376963306\n",
      "GD iter. 16/49: loss=15.385887868829451, w0=73.2939219074533, w1=13.479712417581325\n",
      "GD iter. 17/49: loss=15.3858878688294, w0=73.29392197370963, w1=13.479712429766732\n",
      "GD iter. 18/49: loss=15.385887868829405, w0=73.29392199358652, w1=13.479712433422353\n",
      "GD iter. 19/49: loss=15.385887868829403, w0=73.29392199954958, w1=13.47971243451904\n",
      "GD iter. 20/49: loss=15.3858878688294, w0=73.2939220013385, w1=13.479712434848047\n",
      "GD iter. 21/49: loss=15.385887868829402, w0=73.29392200187519, w1=13.479712434946748\n",
      "GD iter. 22/49: loss=15.385887868829403, w0=73.29392200203618, w1=13.479712434976358\n",
      "GD iter. 23/49: loss=15.3858878688294, w0=73.29392200208449, w1=13.479712434985242\n",
      "GD iter. 24/49: loss=15.3858878688294, w0=73.29392200209898, w1=13.479712434987906\n",
      "GD iter. 25/49: loss=15.385887868829402, w0=73.29392200210333, w1=13.479712434988706\n",
      "GD iter. 26/49: loss=15.385887868829403, w0=73.29392200210464, w1=13.479712434988945\n",
      "GD iter. 27/49: loss=15.385887868829398, w0=73.29392200210502, w1=13.479712434989018\n",
      "GD iter. 28/49: loss=15.385887868829396, w0=73.29392200210513, w1=13.47971243498904\n",
      "GD iter. 29/49: loss=15.385887868829403, w0=73.29392200210518, w1=13.479712434989047\n",
      "GD iter. 30/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.039 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04c2b33631d4b68afc5e01a565458a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # implement stochastic gradient computation. It's the same as the usual gradient.\n",
    "    return compute_gradient(y, tx, w) \n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # implement stochastic gradient descent.\n",
    "        # ***************************************************\n",
    "        # compute gradient and loss\n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "            w = w - gamma * compute_stoch_gradient(minibatch_y, minibatch_tx, w)\n",
    "            \n",
    "        loss = compute_loss(y, tx, w)\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=2030.2433035234058, w0=9.889810912200023, w1=10.37591988262392\n",
      "SGD iter. 1/49: loss=1712.5651867469114, w0=15.713825627006349, w1=4.597646279499401\n",
      "SGD iter. 2/49: loss=1302.2006600959564, w0=22.742271900851552, w1=17.741192986942366\n",
      "SGD iter. 3/49: loss=1078.688345588763, w0=27.669849067627162, w1=20.19155899978\n",
      "SGD iter. 4/49: loss=885.0847894279175, w0=32.15387388898994, w1=20.327649669568373\n",
      "SGD iter. 5/49: loss=760.4581198235437, w0=35.87361906994599, w1=22.959448316060055\n",
      "SGD iter. 6/49: loss=675.1502599629882, w0=38.393972944080524, w1=23.555539941233874\n",
      "SGD iter. 7/49: loss=598.2537028650312, w0=41.66087040539035, w1=26.32827954077867\n",
      "SGD iter. 8/49: loss=558.4161298457786, w0=43.61034508316855, w1=27.79563871488688\n",
      "SGD iter. 9/49: loss=334.68936757852276, w0=48.86836437962033, w1=19.960383252895028\n",
      "SGD iter. 10/49: loss=244.12414879060293, w0=52.12596823350623, w1=16.544717344284308\n",
      "SGD iter. 11/49: loss=198.18402308663264, w0=54.33764206616182, w1=15.980856458382585\n",
      "SGD iter. 12/49: loss=166.1227342594898, w0=56.58147700532779, w1=18.187989721960435\n",
      "SGD iter. 13/49: loss=125.0470781675524, w0=58.716538453041565, w1=16.091659881040577\n",
      "SGD iter. 14/49: loss=120.29858317339499, w0=59.205512261955725, w1=16.847516111391926\n",
      "SGD iter. 15/49: loss=103.83713360020516, w0=60.26472846295674, w1=16.152278090340424\n",
      "SGD iter. 16/49: loss=85.60992006651833, w0=61.45450336415598, w1=14.00528898579665\n",
      "SGD iter. 17/49: loss=65.3818301797309, w0=63.29591372347095, w1=13.657799723037021\n",
      "SGD iter. 18/49: loss=51.55872609240475, w0=64.90191566793503, w1=14.865319209798756\n",
      "SGD iter. 19/49: loss=49.64981803291282, w0=65.08737621741888, w1=14.5662052384692\n",
      "SGD iter. 20/49: loss=43.986273625769954, w0=66.0533177659905, w1=15.664757471101366\n",
      "SGD iter. 21/49: loss=38.67063569144952, w0=67.01978377988004, w1=16.163866904026488\n",
      "SGD iter. 22/49: loss=37.775276471792, w0=67.14988571188191, w1=16.131050827262747\n",
      "SGD iter. 23/49: loss=35.12386800329512, w0=67.46855573274827, w1=15.833659778658841\n",
      "SGD iter. 24/49: loss=34.32537359374319, w0=67.9101166202285, w1=16.46192823199353\n",
      "SGD iter. 25/49: loss=33.494638230310166, w0=68.18461653326916, w1=16.659727898643865\n",
      "SGD iter. 26/49: loss=27.84841577801771, w0=69.66537097848806, w1=16.90880463080176\n",
      "SGD iter. 27/49: loss=17.53853981831155, w0=71.22627738877269, w1=13.653348986214231\n",
      "SGD iter. 28/49: loss=17.99703059082416, w0=71.03086485616173, w1=13.79729360285601\n",
      "SGD iter. 29/49: loss=18.909166705007404, w0=70.67659785023316, w1=13.922625469775113\n",
      "SGD iter. 30/49: loss=18.092240214427388, w0=70.99673819202945, w1=13.84802104732644\n",
      "SGD iter. 31/49: loss=17.681232413082277, w0=71.242053518839, w1=14.096579370303832\n",
      "SGD iter. 32/49: loss=17.843946544471514, w0=71.19127696971839, w1=14.183275665312607\n",
      "SGD iter. 33/49: loss=17.690433444091337, w0=71.42388722521436, w1=14.534255503688822\n",
      "SGD iter. 34/49: loss=18.795232504284698, w0=70.96733043877546, w1=14.66531817399064\n",
      "SGD iter. 35/49: loss=17.60451750292971, w0=72.06874082452526, w1=15.19324397841172\n",
      "SGD iter. 36/49: loss=17.9809974349252, w0=71.85999848825564, w1=15.250046439808749\n",
      "SGD iter. 37/49: loss=16.866778127151072, w0=72.56317104546383, w1=15.037847074874533\n",
      "SGD iter. 38/49: loss=15.811674343638613, w0=73.06987329072334, w1=14.374908013925044\n",
      "SGD iter. 39/49: loss=16.05398101080069, w0=72.2440147093543, w1=13.963324842368221\n",
      "SGD iter. 40/49: loss=15.938341613552554, w0=72.34146501834877, w1=13.924384430441803\n",
      "SGD iter. 41/49: loss=16.16247383903717, w0=72.0963105824526, w1=13.824529528436063\n",
      "SGD iter. 42/49: loss=17.170585768543496, w0=71.50864044973524, w1=14.09790785570626\n",
      "SGD iter. 43/49: loss=16.4033041490485, w0=72.0157971901212, w1=14.113139246411722\n",
      "SGD iter. 44/49: loss=15.619292953575854, w0=72.77228528704777, w1=13.038458191953357\n",
      "SGD iter. 45/49: loss=15.771929480222434, w0=73.03478513772608, w1=12.640110560106775\n",
      "SGD iter. 46/49: loss=15.60309919264309, w0=73.37674882293403, w1=12.825829903200066\n",
      "SGD iter. 47/49: loss=15.962003517055393, w0=72.58988058342074, w1=12.669430399381211\n",
      "SGD iter. 48/49: loss=15.853360010361442, w0=72.77004510607611, w1=12.667002596934275\n",
      "SGD iter. 49/49: loss=16.275635548055973, w0=71.96128493535042, w1=13.539493759534363\n",
      "SGD: execution time=0.087 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ea33ab145e411085a3a91453a7f3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# reload the data by subsampling first, then by subsampling and adding outliers\n",
    "# ***************************************************\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=True)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202,), (202, 2))"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2869.835114535854, w0=51.84746409844846, w1=7.724426406192428\n",
      "GD iter. 1/49: loss=318.2821247015954, w0=67.40170332798299, w1=10.041754328050121\n",
      "GD iter. 2/49: loss=88.6423556165127, w0=72.06797509684336, w1=10.736952704607413\n",
      "GD iter. 3/49: loss=67.9747763988552, w0=73.46785662750146, w1=10.945512217574597\n",
      "GD iter. 4/49: loss=66.11469426926604, w0=73.88782108669889, w1=11.00808007146475\n",
      "GD iter. 5/49: loss=65.94728687760302, w0=74.01381042445813, w1=11.026850427631794\n",
      "GD iter. 6/49: loss=65.93222021235334, w0=74.0516072257859, w1=11.03248153448191\n",
      "GD iter. 7/49: loss=65.93086421248088, w0=74.06294626618423, w1=11.034170866536943\n",
      "GD iter. 8/49: loss=65.93074217249236, w0=74.06634797830372, w1=11.034677666153454\n",
      "GD iter. 9/49: loss=65.93073118889338, w0=74.06736849193958, w1=11.034829706038408\n",
      "GD iter. 10/49: loss=65.93073020036948, w0=74.06767464603033, w1=11.034875318003893\n",
      "GD iter. 11/49: loss=65.93073011140234, w0=74.06776649225755, w1=11.03488900159354\n",
      "GD iter. 12/49: loss=65.93073010339528, w0=74.06779404612573, w1=11.034893106670433\n",
      "GD iter. 13/49: loss=65.93073010267466, w0=74.06780231228618, w1=11.034894338193501\n",
      "GD iter. 14/49: loss=65.93073010260979, w0=74.06780479213431, w1=11.034894707650421\n",
      "GD iter. 15/49: loss=65.93073010260395, w0=74.06780553608876, w1=11.034894818487498\n",
      "GD iter. 16/49: loss=65.93073010260343, w0=74.06780575927509, w1=11.03489485173862\n",
      "GD iter. 17/49: loss=65.93073010260338, w0=74.06780582623098, w1=11.034894861713957\n",
      "GD iter. 18/49: loss=65.93073010260338, w0=74.06780584631775, w1=11.034894864706558\n",
      "GD iter. 19/49: loss=65.93073010260338, w0=74.06780585234378, w1=11.034894865604338\n",
      "GD iter. 20/49: loss=65.93073010260338, w0=74.06780585415159, w1=11.034894865873673\n",
      "GD iter. 21/49: loss=65.93073010260339, w0=74.06780585469393, w1=11.034894865954472\n",
      "GD iter. 22/49: loss=65.93073010260338, w0=74.06780585485663, w1=11.034894865978712\n",
      "GD iter. 23/49: loss=65.93073010260338, w0=74.06780585490544, w1=11.034894865985985\n",
      "GD iter. 24/49: loss=65.93073010260338, w0=74.0678058549201, w1=11.034894865988166\n",
      "GD iter. 25/49: loss=65.93073010260338, w0=74.06780585492449, w1=11.034894865988822\n",
      "GD iter. 26/49: loss=65.93073010260338, w0=74.06780585492581, w1=11.034894865989017\n",
      "GD iter. 27/49: loss=65.93073010260338, w0=74.06780585492619, w1=11.034894865989076\n",
      "GD iter. 28/49: loss=65.93073010260338, w0=74.06780585492632, w1=11.034894865989093\n",
      "GD iter. 29/49: loss=65.93073010260338, w0=74.06780585492635, w1=11.0348948659891\n",
      "GD iter. 30/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 31/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 32/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 33/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 34/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 35/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 36/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 37/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 38/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 39/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 40/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 41/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 42/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 43/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 44/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 45/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 46/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 47/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 48/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 49/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD: execution time=0.003 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# ***************************************************\n",
    "# fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points\n",
    "# and the model fit\n",
    "# ***************************************************\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2cbbd2e9ef4c0a9fb63b605795866b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.06780585492639"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_loss_mae(y, tx, w):\n",
    "    \"\"\"Calculate the loss using MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    e = y - tx @ w\n",
    "    N = y.shape[0]\n",
    "    # ***************************************************\n",
    "    return (1/N) * np.sum(np.abs(e))\n",
    "\n",
    "compute_loss_mae(y, tx, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0000000e+00, -8.7278919e-16])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # compute subgradient gradient vector for MAE\n",
    "    # ***************************************************\n",
    "    N = y.shape[0]\n",
    "    e= y - tx @ w\n",
    "    subgrads = np.repeat(np.reshape(np.sign(e), [N, 1]), 2, axis=1) * (-tx)\n",
    "    return (1/N) * np.sum(subgrads, axis=0)\n",
    "\n",
    "compute_subgradient_mae(y, tx ,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # compute subgradient and loss\n",
    "        # ***************************************************\n",
    "        subgrad = compute_subgradient_mae(y, tx, w)\n",
    "        loss = compute_loss_mae(y, tx, w)\n",
    "\n",
    "        # ***************************************************\n",
    "        # update w by subgradient\n",
    "        # ***************************************************\n",
    "        w = w - gamma * subgrad\n",
    "        \n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3569fa0090417ba71b2453dbe8602d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic subgradient descent.\n",
    "        # ***************************************************\n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "            w = w - gamma * compute_subgradient_mae(minibatch_y, minibatch_tx, w)\n",
    "            \n",
    "        loss = compute_loss(y, tx, w)\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=2823.1870447247356, w0=0.7, w1=-0.44019525470697124\n",
      "SubSGD iter. 1/499: loss=2769.2339025780057, w0=1.4, w1=-0.18991413824491488\n",
      "SubSGD iter. 2/499: loss=2720.695565638388, w0=2.0999999999999996, w1=-0.3740749165632348\n",
      "SubSGD iter. 3/499: loss=2666.700763813956, w0=2.8, w1=-0.03036229537984425\n",
      "SubSGD iter. 4/499: loss=2617.3237750767557, w0=3.5, w1=-0.05432813518293515\n",
      "SubSGD iter. 5/499: loss=2560.018286172528, w0=4.2, w1=0.7070288154361342\n",
      "SubSGD iter. 6/499: loss=2515.9989856319157, w0=4.9, w1=0.2668335607291629\n",
      "SubSGD iter. 7/499: loss=2480.155327748245, w0=5.6000000000000005, w1=-0.8229614623440573\n",
      "SubSGD iter. 8/499: loss=2439.170397817895, w0=6.300000000000001, w1=-1.3749328942817365\n",
      "SubSGD iter. 9/499: loss=2393.472957498174, w0=7.000000000000001, w1=-1.4948247077700676\n",
      "SubSGD iter. 10/499: loss=2330.594913914407, w0=7.700000000000001, w1=-0.1294552551064565\n",
      "SubSGD iter. 11/499: loss=2278.4893331533144, w0=8.4, w1=0.4115017968646857\n",
      "SubSGD iter. 12/499: loss=2230.698469041001, w0=9.1, w1=0.6080218796431884\n",
      "SubSGD iter. 13/499: loss=2182.7815771554056, w0=9.799999999999999, w1=0.8687341010250522\n",
      "SubSGD iter. 14/499: loss=2143.3379038624353, w0=10.499999999999998, w1=0.3602329832852188\n",
      "SubSGD iter. 15/499: loss=2102.8296620760525, w0=11.199999999999998, w1=0.015055895560220467\n",
      "SubSGD iter. 16/499: loss=2051.1248034985006, w0=11.899999999999997, w1=0.7610415491476175\n",
      "SubSGD iter. 17/499: loss=2001.453653280688, w0=12.599999999999996, w1=1.403971247911413\n",
      "SubSGD iter. 18/499: loss=1957.405546164864, w0=13.299999999999995, w1=1.5362947742652517\n",
      "SubSGD iter. 19/499: loss=1910.2367125209184, w0=13.999999999999995, w1=2.0643505897759002\n",
      "SubSGD iter. 20/499: loss=1872.836866030419, w0=14.699999999999994, w1=1.586302387349777\n",
      "SubSGD iter. 21/499: loss=1821.526466166783, w0=15.399999999999993, w1=2.711432347480084\n",
      "SubSGD iter. 22/499: loss=1782.7649247429003, w0=16.099999999999994, w1=2.467405522770933\n",
      "SubSGD iter. 23/499: loss=1740.319500164983, w0=16.799999999999994, w1=2.7176866392329893\n",
      "SubSGD iter. 24/499: loss=1709.6444755058794, w0=17.499999999999993, w1=1.6801724454194487\n",
      "SubSGD iter. 25/499: loss=1673.6268118988019, w0=18.199999999999992, w1=1.3302345139391314\n",
      "SubSGD iter. 26/499: loss=1628.7316127423812, w0=18.89999999999999, w1=1.973164212702927\n",
      "SubSGD iter. 27/499: loss=1585.7465482982468, w0=19.59999999999999, w1=2.4973447641546453\n",
      "SubSGD iter. 28/499: loss=1543.4952026904582, w0=20.29999999999999, w1=3.025400579665294\n",
      "SubSGD iter. 29/499: loss=1504.0115891940063, w0=20.99999999999999, w1=3.2908842818895243\n",
      "SubSGD iter. 30/499: loss=1469.8802764186635, w0=21.69999999999999, w1=2.9409463504092073\n",
      "SubSGD iter. 31/499: loss=1437.1232905806546, w0=22.399999999999988, w1=2.501257945324023\n",
      "SubSGD iter. 32/499: loss=1401.070313574713, w0=23.099999999999987, w1=2.516565612036159\n",
      "SubSGD iter. 33/499: loss=1369.4092232428266, w0=23.799999999999986, w1=2.0847730337527386\n",
      "SubSGD iter. 34/499: loss=1330.0391189176464, w0=24.499999999999986, w1=2.593958877698991\n",
      "SubSGD iter. 35/499: loss=1299.736094137116, w0=25.199999999999985, w1=2.115910675272868\n",
      "SubSGD iter. 36/499: loss=1256.4247477354788, w0=25.899999999999984, w1=3.2342208958843495\n",
      "SubSGD iter. 37/499: loss=1234.4306595724095, w0=26.599999999999984, w1=1.8802640018511219\n",
      "SubSGD iter. 38/499: loss=1205.1464584625091, w0=27.299999999999983, w1=1.484827209908116\n",
      "SubSGD iter. 39/499: loss=1179.6199735161792, w0=27.999999999999982, w1=0.7813222915172533\n",
      "SubSGD iter. 40/499: loss=1156.1384964983117, w0=28.69999999999998, w1=-0.01850844254545625\n",
      "SubSGD iter. 41/499: loss=1128.5552657674136, w0=29.39999999999998, w1=-0.36844637402577346\n",
      "SubSGD iter. 42/499: loss=1090.5226460801089, w0=30.09999999999998, w1=0.2638280544559172\n",
      "SubSGD iter. 43/499: loss=1093.6665453101136, w0=30.79999999999998, w1=-2.506471642433072\n",
      "SubSGD iter. 44/499: loss=1065.3520967010104, w0=31.49999999999998, w1=-2.633486087661097\n",
      "SubSGD iter. 45/499: loss=1041.7741613280461, w0=32.19999999999998, w1=-3.063817676121833\n",
      "SubSGD iter. 46/499: loss=1006.2423393984434, w0=32.899999999999984, w1=-2.5972355501552578\n",
      "SubSGD iter. 47/499: loss=983.5648945108624, w0=33.59999999999999, w1=-3.023021697445997\n",
      "SubSGD iter. 48/499: loss=952.7390775571421, w0=34.29999999999999, w1=-2.826501614667494\n",
      "SubSGD iter. 49/499: loss=928.0068704756442, w0=34.99999999999999, w1=-3.0313351345427173\n",
      "SubSGD iter. 50/499: loss=892.571922893827, w0=35.699999999999996, w1=-2.4259319830987325\n",
      "SubSGD iter. 51/499: loss=866.4270281740808, w0=36.4, w1=-2.4606228424402037\n",
      "SubSGD iter. 52/499: loss=846.1414154880109, w0=37.1, w1=-2.886408989730943\n",
      "SubSGD iter. 53/499: loss=804.9267617412809, w0=37.800000000000004, w1=-1.7180781892134742\n",
      "SubSGD iter. 54/499: loss=790.0931069783898, w0=38.50000000000001, w1=-2.5023109172527986\n",
      "SubSGD iter. 55/499: loss=752.929182412467, w0=39.20000000000001, w1=-1.5441758263509917\n",
      "SubSGD iter. 56/499: loss=726.2407407106799, w0=39.90000000000001, w1=-1.3417389363099925\n",
      "SubSGD iter. 57/499: loss=695.268933649846, w0=40.600000000000016, w1=-0.7372068304558332\n",
      "SubSGD iter. 58/499: loss=671.4251724229697, w0=41.30000000000002, w1=-0.6808972154105297\n",
      "SubSGD iter. 59/499: loss=649.0294116724077, w0=42.00000000000002, w1=-0.706194980799371\n",
      "SubSGD iter. 60/499: loss=629.2041161134684, w0=42.700000000000024, w1=-0.9069445178486224\n",
      "SubSGD iter. 61/499: loss=621.0996357380234, w0=43.40000000000003, w1=-1.9967395409218427\n",
      "SubSGD iter. 62/499: loss=608.9472190156151, w0=44.10000000000003, w1=-2.6750865368963854\n",
      "SubSGD iter. 63/499: loss=587.6353543819819, w0=44.80000000000003, w1=-2.632759980292895\n",
      "SubSGD iter. 64/499: loss=564.2875824505, w0=45.500000000000036, w1=-2.4036382880061367\n",
      "SubSGD iter. 65/499: loss=551.7587242826778, w0=46.20000000000004, w1=-2.9308269267533635\n",
      "SubSGD iter. 66/499: loss=537.4037722126513, w0=46.90000000000004, w1=-3.277910912373354\n",
      "SubSGD iter. 67/499: loss=526.6124291678108, w0=47.600000000000044, w1=-3.825073214607224\n",
      "SubSGD iter. 68/499: loss=504.65208957715265, w0=48.30000000000005, w1=-3.575474751920046\n",
      "SubSGD iter. 69/499: loss=474.71646291820554, w0=49.00000000000005, w1=-2.7192526994155077\n",
      "SubSGD iter. 70/499: loss=460.19528776433185, w0=49.70000000000005, w1=-2.920002236464759\n",
      "SubSGD iter. 71/499: loss=440.62888917628175, w0=50.400000000000055, w1=-2.7212413706462346\n",
      "SubSGD iter. 72/499: loss=430.21813007106, w0=51.10000000000006, w1=-3.144480795418749\n",
      "SubSGD iter. 73/499: loss=425.81310691531587, w0=51.80000000000006, w1=-3.928713523458073\n",
      "SubSGD iter. 74/499: loss=401.05677388139685, w0=52.500000000000064, w1=-3.2857838246942777\n",
      "SubSGD iter. 75/499: loss=375.9585632237799, w0=53.20000000000007, w1=-2.5515080812024786\n",
      "SubSGD iter. 76/499: loss=380.15819231850065, w0=52.500000000000064, w1=-1.7433943401605458\n",
      "SubSGD iter. 77/499: loss=357.619323960262, w0=53.20000000000007, w1=-1.1270073913232963\n",
      "SubSGD iter. 78/499: loss=347.5144434751339, w0=53.90000000000007, w1=-1.4721844790482947\n",
      "SubSGD iter. 79/499: loss=323.0260873913182, w0=54.60000000000007, w1=-0.5924543492158164\n",
      "SubSGD iter. 80/499: loss=315.90957862793636, w0=55.300000000000075, w1=-1.1194113849846643\n",
      "SubSGD iter. 81/499: loss=308.2508619209999, w0=56.00000000000008, w1=-1.5426508097571785\n",
      "SubSGD iter. 82/499: loss=299.44207255772614, w0=56.70000000000008, w1=-1.8251986288434037\n",
      "SubSGD iter. 83/499: loss=291.20311646452274, w0=57.400000000000084, w1=-2.107746447929629\n",
      "SubSGD iter. 84/499: loss=295.0990442552857, w0=56.70000000000008, w1=-1.4829303481186829\n",
      "SubSGD iter. 85/499: loss=287.8340608969282, w0=57.400000000000084, w1=-1.8488510788490802\n",
      "SubSGD iter. 86/499: loss=267.22095509961446, w0=58.10000000000009, w1=-1.1145753353572811\n",
      "SubSGD iter. 87/499: loss=263.17411570976924, w0=58.80000000000009, w1=-1.668682409353862\n",
      "SubSGD iter. 88/499: loss=257.06123445637, w0=59.50000000000009, w1=-2.005045367029939\n",
      "SubSGD iter. 89/499: loss=247.56173881822738, w0=60.200000000000095, w1=-2.03973622637141\n",
      "SubSGD iter. 90/499: loss=228.79699377007137, w0=60.9000000000001, w1=-1.307771632863775\n",
      "SubSGD iter. 91/499: loss=224.99631148831259, w0=60.200000000000095, w1=-0.18183921936260417\n",
      "SubSGD iter. 92/499: loss=230.70136777179133, w0=59.50000000000009, w1=0.20344492096552386\n",
      "SubSGD iter. 93/499: loss=236.5601145872605, w0=58.80000000000009, w1=0.6352374992489442\n",
      "SubSGD iter. 94/499: loss=225.20091324131798, w0=59.50000000000009, w1=0.7237650127380701\n",
      "SubSGD iter. 95/499: loss=213.55613123384848, w0=60.200000000000095, w1=0.889217804670696\n",
      "SubSGD iter. 96/499: loss=205.32352807258897, w0=60.9000000000001, w1=0.7687132531916536\n",
      "SubSGD iter. 97/499: loss=190.1445903966446, w0=61.6000000000001, w1=1.392201375477831\n",
      "SubSGD iter. 98/499: loss=179.4790244223858, w0=62.300000000000104, w1=1.6213230677645891\n",
      "SubSGD iter. 99/499: loss=180.44085719722605, w0=61.6000000000001, w1=2.457361925037405\n",
      "SubSGD iter. 100/499: loss=184.26528183025658, w0=60.9000000000001, w1=3.080148331857697\n",
      "SubSGD iter. 101/499: loss=172.61774013269275, w0=61.6000000000001, w1=3.4238609530410877\n",
      "SubSGD iter. 102/499: loss=156.20483246481004, w0=62.300000000000104, w1=4.548990913171394\n",
      "SubSGD iter. 103/499: loss=151.88175441823134, w0=63.00000000000011, w1=4.005974451806296\n",
      "SubSGD iter. 104/499: loss=140.67503726316988, w0=63.70000000000011, w1=4.554368955564106\n",
      "SubSGD iter. 105/499: loss=130.57347703689942, w0=64.4000000000001, w1=5.049995216032939\n",
      "SubSGD iter. 106/499: loss=124.19473326543815, w0=65.10000000000011, w1=5.0260293762298485\n",
      "SubSGD iter. 107/499: loss=123.65744328166734, w0=65.80000000000011, w1=4.17218310580458\n",
      "SubSGD iter. 108/499: loss=130.0779294238719, w0=65.10000000000011, w1=4.115873490759276\n",
      "SubSGD iter. 109/499: loss=116.57260223190654, w0=65.80000000000011, w1=5.296678191459172\n",
      "SubSGD iter. 110/499: loss=122.52623063815513, w0=65.10000000000011, w1=5.310433387434663\n",
      "SubSGD iter. 111/499: loss=112.7269511067622, w0=65.80000000000011, w1=6.011367384869415\n",
      "SubSGD iter. 112/499: loss=110.39978918657962, w0=66.50000000000011, w1=5.407601314902902\n",
      "SubSGD iter. 113/499: loss=111.8366559978456, w0=65.80000000000011, w1=6.191834042942226\n",
      "SubSGD iter. 114/499: loss=105.33426807532491, w0=66.50000000000011, w1=6.394270932983225\n",
      "SubSGD iter. 115/499: loss=98.78232556495243, w0=67.20000000000012, w1=6.72949898828648\n",
      "SubSGD iter. 116/499: loss=101.13614838986558, w0=66.50000000000011, w1=7.410098165942562\n",
      "SubSGD iter. 117/499: loss=97.54182343325157, w0=67.20000000000012, w1=7.027972181392228\n",
      "SubSGD iter. 118/499: loss=91.93342284151808, w0=67.90000000000012, w1=7.298110631681897\n",
      "SubSGD iter. 119/499: loss=85.02799977780214, w0=68.60000000000012, w1=8.154332684186436\n",
      "SubSGD iter. 120/499: loss=87.49583982784512, w0=67.90000000000012, w1=8.779148783997382\n",
      "SubSGD iter. 121/499: loss=82.06126090497499, w0=68.60000000000012, w1=9.49731210802857\n",
      "SubSGD iter. 122/499: loss=77.51310147790535, w0=69.30000000000013, w1=10.377042237861048\n",
      "SubSGD iter. 123/499: loss=74.21530324564895, w0=70.00000000000013, w1=10.8862280818073\n",
      "SubSGD iter. 124/499: loss=71.6327747693877, w0=70.70000000000013, w1=10.78595098256709\n",
      "SubSGD iter. 125/499: loss=70.31681133463503, w0=71.40000000000013, w1=9.74843678875355\n",
      "SubSGD iter. 126/499: loss=71.75433005226205, w0=70.70000000000013, w1=10.482551111754539\n",
      "SubSGD iter. 127/499: loss=74.23971407652286, w0=70.00000000000013, w1=11.301209481560168\n",
      "SubSGD iter. 128/499: loss=77.48484535970942, w0=69.30000000000013, w1=11.648293467180158\n",
      "SubSGD iter. 129/499: loss=80.87921249979456, w0=68.60000000000012, w1=11.042890315736173\n",
      "SubSGD iter. 130/499: loss=77.48952945285441, w0=69.30000000000013, w1=11.655882812919733\n",
      "SubSGD iter. 131/499: loss=74.21125509134767, w0=70.00000000000013, w1=10.916550013475788\n",
      "SubSGD iter. 132/499: loss=71.87373104678566, w0=70.70000000000013, w1=10.297408858061406\n",
      "SubSGD iter. 133/499: loss=74.22641356334859, w0=70.00000000000013, w1=10.824365893830254\n",
      "SubSGD iter. 134/499: loss=71.75884981587853, w0=70.70000000000013, w1=10.474427962349937\n",
      "SubSGD iter. 135/499: loss=69.64491872553805, w0=71.40000000000013, w1=11.59273818296142\n",
      "SubSGD iter. 136/499: loss=72.09147784343041, w0=70.70000000000013, w1=12.02453076124484\n",
      "SubSGD iter. 137/499: loss=75.96857282574514, w0=70.00000000000013, w1=12.913362585411333\n",
      "SubSGD iter. 138/499: loss=80.21038402684492, w0=69.30000000000013, w1=13.448882268237538\n",
      "SubSGD iter. 139/499: loss=85.20375762993861, w0=68.60000000000012, w1=13.975839304006387\n",
      "SubSGD iter. 140/499: loss=80.65337379619629, w0=69.30000000000013, w1=13.62590137252607\n",
      "SubSGD iter. 141/499: loss=82.0307077045596, w0=70.00000000000013, w1=14.99127082518968\n",
      "SubSGD iter. 142/499: loss=79.63596989401145, w0=70.70000000000013, w1=15.04343117071939\n",
      "SubSGD iter. 143/499: loss=73.90281033417081, w0=71.40000000000013, w1=14.00591697690585\n",
      "SubSGD iter. 144/499: loss=73.6276453185134, w0=70.70000000000013, w1=13.047781886004042\n",
      "SubSGD iter. 145/499: loss=77.42965625313957, w0=70.00000000000013, w1=13.57473892177289\n",
      "SubSGD iter. 146/499: loss=81.88573514454038, w0=69.30000000000013, w1=14.06442245516948\n",
      "SubSGD iter. 147/499: loss=79.64815032530542, w0=70.00000000000013, w1=14.33456090545915\n",
      "SubSGD iter. 148/499: loss=80.33313322566403, w0=70.70000000000013, w1=15.213733217689956\n",
      "SubSGD iter. 149/499: loss=75.0171103126654, w0=71.40000000000013, w1=14.359886947264688\n",
      "SubSGD iter. 150/499: loss=78.10896030719233, w0=70.70000000000013, w1=14.642434766350913\n",
      "SubSGD iter. 151/499: loss=78.56140658232488, w0=71.40000000000013, w1=15.294491663793368\n",
      "SubSGD iter. 152/499: loss=77.60189649256836, w0=72.10000000000014, w1=15.447385420907949\n",
      "SubSGD iter. 153/499: loss=84.450838919299, w0=72.80000000000014, w1=16.987447759295137\n",
      "SubSGD iter. 154/499: loss=79.1316649082959, w0=72.10000000000014, w1=15.781431469524689\n",
      "SubSGD iter. 155/499: loss=79.55063433615513, w0=71.40000000000013, w1=15.520719248142825\n",
      "SubSGD iter. 156/499: loss=77.48337252927939, w0=72.10000000000014, w1=15.420442148902616\n",
      "SubSGD iter. 157/499: loss=80.68822350434324, w0=71.40000000000013, w1=15.767526134522607\n",
      "SubSGD iter. 158/499: loss=78.72519893831922, w0=70.70000000000013, w1=14.8093910436208\n",
      "SubSGD iter. 159/499: loss=82.42343406913056, w0=70.00000000000013, w1=15.089320036057263\n",
      "SubSGD iter. 160/499: loss=89.1188587687677, w0=69.30000000000013, w1=15.897433777099195\n",
      "SubSGD iter. 161/499: loss=83.41736865876247, w0=70.00000000000013, w1=15.32747365256321\n",
      "SubSGD iter. 162/499: loss=87.30703486298641, w0=69.30000000000013, w1=15.509337496138379\n",
      "SubSGD iter. 163/499: loss=81.88876777570698, w0=70.00000000000013, w1=14.955230422141797\n",
      "SubSGD iter. 164/499: loss=77.86125172713037, w0=70.70000000000013, w1=14.573104437591462\n",
      "SubSGD iter. 165/499: loss=82.8611961055142, w0=70.00000000000013, w1=15.195890844411755\n",
      "SubSGD iter. 166/499: loss=80.90661056602782, w0=70.70000000000013, w1=15.348784601526337\n",
      "SubSGD iter. 167/499: loss=80.98548182605096, w0=70.00000000000013, w1=14.717619261531484\n",
      "SubSGD iter. 168/499: loss=79.3125985088307, w0=70.70000000000013, w1=14.961931985240618\n",
      "SubSGD iter. 169/499: loss=84.56393620323409, w0=70.00000000000013, w1=15.586748085051564\n",
      "SubSGD iter. 170/499: loss=90.32122947181617, w0=69.30000000000013, w1=16.138719516989244\n",
      "SubSGD iter. 171/499: loss=87.87699508810041, w0=68.60000000000012, w1=14.775968121597497\n",
      "SubSGD iter. 172/499: loss=93.05698010745952, w0=67.90000000000012, w1=15.06114261614679\n",
      "SubSGD iter. 173/499: loss=93.79584087094361, w0=68.60000000000012, w1=16.11754384752568\n",
      "SubSGD iter. 174/499: loss=98.4848599965838, w0=67.90000000000012, w1=16.23743566101401\n",
      "SubSGD iter. 175/499: loss=98.66321869643488, w0=68.60000000000012, w1=16.998792611633082\n",
      "SubSGD iter. 176/499: loss=92.9653897674882, w0=69.30000000000013, w1=16.632871880902684\n",
      "SubSGD iter. 177/499: loss=87.93961096437386, w0=70.00000000000013, w1=16.276146362546847\n",
      "SubSGD iter. 178/499: loss=80.8370943393129, w0=70.70000000000013, w1=15.332639879009726\n",
      "SubSGD iter. 179/499: loss=79.36873129467185, w0=70.00000000000013, w1=14.248764482318425\n",
      "SubSGD iter. 180/499: loss=81.0152469030995, w0=70.70000000000013, w1=15.373894442448732\n",
      "SubSGD iter. 181/499: loss=75.85526594704734, w0=71.40000000000013, w1=14.603071376380544\n",
      "SubSGD iter. 182/499: loss=79.4167137992351, w0=70.70000000000013, w1=14.988355516708673\n",
      "SubSGD iter. 183/499: loss=75.980574403662, w0=71.40000000000013, w1=14.638018583340282\n",
      "SubSGD iter. 184/499: loss=74.45348198651982, w0=72.10000000000014, w1=14.664391233965102\n",
      "SubSGD iter. 185/499: loss=71.06443696380981, w0=72.80000000000014, w1=13.977696598458966\n",
      "SubSGD iter. 186/499: loss=72.11535790623427, w0=73.50000000000014, w1=14.505752413969615\n",
      "SubSGD iter. 187/499: loss=74.31639156209813, w0=72.80000000000014, w1=14.92899183874213\n",
      "SubSGD iter. 188/499: loss=71.26245580362303, w0=73.50000000000014, w1=14.250644842767587\n",
      "SubSGD iter. 189/499: loss=74.87262129898977, w0=72.80000000000014, w1=15.069303212573216\n",
      "SubSGD iter. 190/499: loss=77.19625800465141, w0=72.10000000000014, w1=15.35447770712251\n",
      "SubSGD iter. 191/499: loss=79.34651216941072, w0=71.40000000000013, w1=15.474982258601552\n",
      "SubSGD iter. 192/499: loss=78.95418985557396, w0=70.70000000000013, w1=14.869579107157566\n",
      "SubSGD iter. 193/499: loss=74.95908772241062, w0=71.40000000000013, w1=14.34239046841034\n",
      "SubSGD iter. 194/499: loss=71.73191345007143, w0=72.10000000000014, w1=13.815201829663113\n",
      "SubSGD iter. 195/499: loss=72.87805517292139, w0=72.80000000000014, w1=14.540222019743917\n",
      "SubSGD iter. 196/499: loss=73.8744369274389, w0=73.50000000000014, w1=14.980146462628099\n",
      "SubSGD iter. 197/499: loss=74.35080787956406, w0=72.80000000000014, w1=14.937819906024608\n",
      "SubSGD iter. 198/499: loss=74.16064860096122, w0=72.10000000000014, w1=14.582792428494782\n",
      "SubSGD iter. 199/499: loss=77.70238533389973, w0=71.40000000000013, w1=15.087810160319105\n",
      "SubSGD iter. 200/499: loss=78.8423614133145, w0=72.10000000000014, w1=15.720084588800795\n",
      "SubSGD iter. 201/499: loss=79.25931261645329, w0=71.40000000000013, w1=15.455299479610026\n",
      "SubSGD iter. 202/499: loss=78.86745716114424, w0=72.10000000000014, w1=15.725437929899696\n",
      "SubSGD iter. 203/499: loss=80.33106713780468, w0=72.80000000000014, w1=16.249618481351416\n",
      "SubSGD iter. 204/499: loss=83.69150556486062, w0=73.50000000000014, w1=16.967781805382604\n",
      "SubSGD iter. 205/499: loss=81.0785254436387, w0=74.20000000000014, w1=16.53745021692187\n",
      "SubSGD iter. 206/499: loss=79.6851327110957, w0=73.50000000000014, w1=16.24895295236445\n",
      "SubSGD iter. 207/499: loss=74.15067755950352, w0=72.80000000000014, w1=14.886201556972704\n",
      "SubSGD iter. 208/499: loss=79.36197673322309, w0=72.10000000000014, w1=15.829708040509825\n",
      "SubSGD iter. 209/499: loss=82.39246150134443, w0=71.40000000000013, w1=16.11488253505912\n",
      "SubSGD iter. 210/499: loss=76.03765594302044, w0=72.10000000000014, w1=15.07736834124558\n",
      "SubSGD iter. 211/499: loss=77.29453047945552, w0=72.80000000000014, w1=15.630574257321692\n",
      "SubSGD iter. 212/499: loss=79.12175638222689, w0=73.50000000000014, w1=16.139760101267946\n",
      "SubSGD iter. 213/499: loss=79.47835287079181, w0=72.80000000000014, w1=16.08345048622264\n",
      "SubSGD iter. 214/499: loss=82.68538673586224, w0=72.10000000000014, w1=16.478887278165647\n",
      "SubSGD iter. 215/499: loss=81.19951217062768, w0=71.40000000000013, w1=15.874355172311487\n",
      "SubSGD iter. 216/499: loss=83.37863859671329, w0=70.70000000000013, w1=15.888110368286977\n",
      "SubSGD iter. 217/499: loss=82.99335510270797, w0=71.40000000000013, w1=16.231822989470366\n",
      "SubSGD iter. 218/499: loss=77.60280037042159, w0=72.10000000000014, w1=15.447590261431042\n",
      "SubSGD iter. 219/499: loss=82.1775851747952, w0=71.40000000000013, w1=16.07240636124199\n",
      "SubSGD iter. 220/499: loss=83.06057559064996, w0=70.70000000000013, w1=15.822125244779931\n",
      "SubSGD iter. 221/499: loss=78.32158333252022, w0=71.40000000000013, w1=15.23781270723404\n",
      "SubSGD iter. 222/499: loss=77.68834725733828, w0=72.10000000000014, w1=15.466934399520799\n",
      "SubSGD iter. 223/499: loss=79.98895989964618, w0=71.40000000000013, w1=15.617391075971927\n",
      "SubSGD iter. 224/499: loss=79.07881911418772, w0=72.10000000000014, w1=15.770284833086508\n",
      "SubSGD iter. 225/499: loss=78.47475173625085, w0=72.80000000000014, w1=15.8805848665473\n",
      "SubSGD iter. 226/499: loss=76.12609820249439, w0=73.50000000000014, w1=15.514664135816902\n",
      "SubSGD iter. 227/499: loss=80.77106367171172, w0=72.80000000000014, w1=16.33332250562253\n",
      "SubSGD iter. 228/499: loss=83.57424036555089, w0=73.50000000000014, w1=16.947983486752918\n",
      "SubSGD iter. 229/499: loss=85.53987678220133, w0=74.20000000000014, w1=17.295950533143333\n",
      "SubSGD iter. 230/499: loss=90.24927636072974, w0=74.90000000000015, w1=17.959094850186382\n",
      "SubSGD iter. 231/499: loss=86.49613529657861, w0=75.60000000000015, w1=17.26251009894562\n",
      "SubSGD iter. 232/499: loss=88.83805500837539, w0=74.90000000000015, w1=17.752193632342205\n",
      "SubSGD iter. 233/499: loss=90.45678363342581, w0=74.20000000000014, w1=18.0373681268915\n",
      "SubSGD iter. 234/499: loss=84.63254285475904, w0=74.90000000000015, w1=17.09386164335438\n",
      "SubSGD iter. 235/499: loss=87.7325590908377, w0=74.20000000000014, w1=17.63687810471948\n",
      "SubSGD iter. 236/499: loss=86.3986139921175, w0=73.50000000000014, w1=17.40775641243272\n",
      "SubSGD iter. 237/499: loss=79.28499780833249, w0=72.80000000000014, w1=16.045005017040975\n",
      "SubSGD iter. 238/499: loss=81.08901099562439, w0=73.50000000000014, w1=16.51158714300755\n",
      "SubSGD iter. 239/499: loss=83.60072306318776, w0=74.20000000000014, w1=16.978169268974124\n",
      "SubSGD iter. 240/499: loss=78.03269654472952, w0=73.50000000000014, w1=15.921768037595234\n",
      "SubSGD iter. 241/499: loss=80.09585263500136, w0=72.80000000000014, w1=16.204315856681458\n",
      "SubSGD iter. 242/499: loss=83.55365676658353, w0=72.10000000000014, w1=16.63610843496488\n",
      "SubSGD iter. 243/499: loss=85.5975259139077, w0=72.80000000000014, w1=17.17706548693602\n",
      "SubSGD iter. 244/499: loss=82.40448441356398, w0=73.50000000000014, w1=16.746733898475284\n",
      "SubSGD iter. 245/499: loss=77.05612947247971, w0=72.80000000000014, w1=15.578403097957816\n",
      "SubSGD iter. 246/499: loss=73.11995304584727, w0=73.50000000000014, w1=14.784033753467035\n",
      "SubSGD iter. 247/499: loss=75.87689411789985, w0=72.80000000000014, w1=15.310990789235884\n",
      "SubSGD iter. 248/499: loss=77.06827135649063, w0=72.10000000000014, w1=15.324745985211374\n",
      "SubSGD iter. 249/499: loss=81.72440331254789, w0=71.40000000000013, w1=15.981626952964337\n",
      "SubSGD iter. 250/499: loss=85.07377728045653, w0=70.70000000000013, w1=16.22565377767349\n",
      "SubSGD iter. 251/499: loss=90.27193938778441, w0=70.00000000000013, w1=16.703701980099613\n",
      "SubSGD iter. 252/499: loss=84.82109935491215, w0=70.70000000000013, w1=16.176744944330764\n",
      "SubSGD iter. 253/499: loss=84.55337358143102, w0=70.00000000000013, w1=15.584426983062587\n",
      "SubSGD iter. 254/499: loss=90.67315589404518, w0=69.30000000000013, w1=16.207213389882877\n",
      "SubSGD iter. 255/499: loss=97.26292828540264, w0=68.60000000000012, w1=16.759184821820558\n",
      "SubSGD iter. 256/499: loss=96.3493660828042, w0=69.30000000000013, w1=17.20784386060527\n",
      "SubSGD iter. 257/499: loss=102.99706239371841, w0=68.60000000000012, w1=17.685892063031392\n",
      "SubSGD iter. 258/499: loss=97.74834429296979, w0=69.30000000000013, w1=17.43046018192982\n",
      "SubSGD iter. 259/499: loss=90.88779038044564, w0=70.00000000000013, w1=16.811319026515438\n",
      "SubSGD iter. 260/499: loss=96.03371735903396, w0=69.30000000000013, w1=17.156496114240436\n",
      "SubSGD iter. 261/499: loss=92.20250649721706, w0=68.60000000000012, w1=15.79374471884869\n",
      "SubSGD iter. 262/499: loss=86.87457234745177, w0=69.30000000000013, w1=15.411618734298354\n",
      "SubSGD iter. 263/499: loss=80.28694779508665, w0=70.00000000000013, w1=14.522786910131861\n",
      "SubSGD iter. 264/499: loss=77.83300992536849, w0=70.70000000000013, w1=14.565113466735353\n",
      "SubSGD iter. 265/499: loss=76.45568264884481, w0=71.40000000000013, w1=14.767550356776352\n",
      "SubSGD iter. 266/499: loss=73.43357424451122, w0=72.10000000000014, w1=14.37157411355452\n",
      "SubSGD iter. 267/499: loss=76.04823640702787, w0=71.40000000000013, w1=14.656748608103813\n",
      "SubSGD iter. 268/499: loss=79.52102456633176, w0=72.10000000000014, w1=15.86276489787426\n",
      "SubSGD iter. 269/499: loss=81.71682845574604, w0=72.80000000000014, w1=16.508912131261482\n",
      "SubSGD iter. 270/499: loss=83.5127694346651, w0=72.10000000000014, w1=16.628803944749812\n",
      "SubSGD iter. 271/499: loss=86.06240992328881, w0=72.80000000000014, w1=17.252292067035988\n",
      "SubSGD iter. 272/499: loss=83.03640283115001, w0=73.50000000000014, w1=16.856315823814157\n",
      "SubSGD iter. 273/499: loss=87.5113820471158, w0=72.80000000000014, w1=17.481131923625103\n",
      "SubSGD iter. 274/499: loss=82.24432133532915, w0=72.10000000000014, w1=16.397256526933802\n",
      "SubSGD iter. 275/499: loss=77.61913303105919, w0=72.80000000000014, w1=15.700671775693039\n",
      "SubSGD iter. 276/499: loss=75.46384443105438, w0=73.50000000000014, w1=15.364308818016962\n",
      "SubSGD iter. 277/499: loss=78.16140622094113, w0=74.20000000000014, w1=15.978969799147348\n",
      "SubSGD iter. 278/499: loss=76.19631387874074, w0=73.50000000000014, w1=15.530310760362639\n",
      "SubSGD iter. 279/499: loss=75.2359246471168, w0=74.20000000000014, w1=15.34684498131222\n",
      "SubSGD iter. 280/499: loss=76.65870918639492, w0=73.50000000000014, w1=15.632019475861513\n",
      "SubSGD iter. 281/499: loss=81.39974858698115, w0=72.80000000000014, w1=16.45067784566714\n",
      "SubSGD iter. 282/499: loss=84.9139513637821, w0=72.10000000000014, w1=16.873917270439655\n",
      "SubSGD iter. 283/499: loss=85.0367760969943, w0=72.80000000000014, w1=17.08508166500586\n",
      "SubSGD iter. 284/499: loss=88.31719966586465, w0=72.10000000000014, w1=17.430258752730857\n",
      "SubSGD iter. 285/499: loss=93.50789766984626, w0=71.40000000000013, w1=17.965778435557063\n",
      "SubSGD iter. 286/499: loss=100.56912304648573, w0=70.70000000000013, w1=18.646377613213147\n",
      "SubSGD iter. 287/499: loss=95.68879917897686, w0=70.00000000000013, w1=17.58997638183426\n",
      "SubSGD iter. 288/499: loss=94.84310786698828, w0=69.30000000000013, w1=16.958811041839407\n",
      "SubSGD iter. 289/499: loss=96.7773100115806, w0=70.00000000000013, w1=17.753980766956754\n",
      "SubSGD iter. 290/499: loss=102.8031219670925, w0=69.30000000000013, w1=18.17722019172927\n",
      "SubSGD iter. 291/499: loss=104.2838797846241, w0=70.00000000000013, w1=18.79113460510685\n",
      "SubSGD iter. 292/499: loss=102.01060637522072, w0=70.70000000000013, w1=18.833461161710343\n",
      "SubSGD iter. 293/499: loss=107.3800615922467, w0=70.00000000000013, w1=19.180545147330335\n",
      "SubSGD iter. 294/499: loss=97.83968675563324, w0=70.70000000000013, w1=18.278912882917577\n",
      "SubSGD iter. 295/499: loss=104.55549772214077, w0=70.00000000000013, w1=18.82607518515145\n",
      "SubSGD iter. 296/499: loss=100.37811712036807, w0=70.70000000000013, w1=18.621241665276226\n",
      "SubSGD iter. 297/499: loss=92.24573570426898, w0=71.40000000000013, w1=17.781214093816416\n",
      "SubSGD iter. 298/499: loss=87.20709308194748, w0=72.10000000000014, w1=17.254257058047568\n",
      "SubSGD iter. 299/499: loss=87.07690353652372, w0=71.40000000000013, w1=16.96575979349015\n",
      "SubSGD iter. 300/499: loss=87.57872552212523, w0=72.10000000000014, w1=17.313726839880566\n",
      "SubSGD iter. 301/499: loss=90.48181242085508, w0=71.40000000000013, w1=17.514476376929817\n",
      "SubSGD iter. 302/499: loss=84.67937072935455, w0=70.70000000000013, w1=16.149106924266206\n",
      "SubSGD iter. 303/499: loss=90.48181242085508, w0=71.40000000000013, w1=17.514476376929817\n",
      "SubSGD iter. 304/499: loss=85.03924062428516, w0=72.10000000000014, w1=16.895335221515435\n",
      "SubSGD iter. 305/499: loss=85.16780173055724, w0=71.40000000000013, w1=16.63462300013357\n",
      "SubSGD iter. 306/499: loss=82.74097882119565, w0=70.70000000000013, w1=15.754892870301092\n",
      "SubSGD iter. 307/499: loss=78.16664776403479, w0=71.40000000000013, w1=15.20078579630451\n",
      "SubSGD iter. 308/499: loss=76.40961377652165, w0=72.10000000000014, w1=15.16835678853715\n",
      "SubSGD iter. 309/499: loss=79.06894460746466, w0=72.80000000000014, w1=16.001694371096725\n",
      "SubSGD iter. 310/499: loss=83.0952763717323, w0=72.10000000000014, w1=16.553665803034406\n",
      "SubSGD iter. 311/499: loss=83.29150768204087, w0=71.40000000000013, w1=16.288880693843637\n",
      "SubSGD iter. 312/499: loss=77.15697613283788, w0=72.10000000000014, w1=15.345374210306517\n",
      "SubSGD iter. 313/499: loss=79.96382223410912, w0=72.80000000000014, w1=16.178711792866093\n",
      "SubSGD iter. 314/499: loss=78.42581366739762, w0=72.10000000000014, w1=15.630317289108282\n",
      "SubSGD iter. 315/499: loss=82.60870980281172, w0=71.40000000000013, w1=16.15727432487713\n",
      "SubSGD iter. 316/499: loss=86.6848547436319, w0=72.10000000000014, w1=17.16971266274355\n",
      "SubSGD iter. 317/499: loss=82.88834606092962, w0=71.40000000000013, w1=16.211577571841744\n",
      "SubSGD iter. 318/499: loss=76.21818550977142, w0=72.10000000000014, w1=15.121782548768524\n",
      "SubSGD iter. 319/499: loss=77.78316611911302, w0=72.80000000000014, w1=15.735696962146106\n",
      "SubSGD iter. 320/499: loss=78.00104766377815, w0=72.10000000000014, w1=15.536936096327581\n",
      "SubSGD iter. 321/499: loss=78.02343583166447, w0=72.80000000000014, w1=15.78653455901476\n",
      "SubSGD iter. 322/499: loss=74.28691135350849, w0=72.10000000000014, w1=14.618203758497291\n",
      "SubSGD iter. 323/499: loss=76.20222354744223, w0=71.40000000000013, w1=14.699018063986003\n",
      "SubSGD iter. 324/499: loss=77.98043678026617, w0=72.10000000000014, w1=15.532355646545579\n",
      "SubSGD iter. 325/499: loss=79.79276229747794, w0=72.80000000000014, w1=16.145348143729137\n",
      "SubSGD iter. 326/499: loss=83.80536537966691, w0=72.10000000000014, w1=16.680867826555343\n",
      "SubSGD iter. 327/499: loss=82.4819772040514, w0=71.40000000000013, w1=16.13247332279753\n",
      "SubSGD iter. 328/499: loss=78.18842614715943, w0=72.10000000000014, w1=15.578366248800949\n",
      "SubSGD iter. 329/499: loss=74.20398920835822, w0=72.80000000000014, w1=14.900019252826405\n",
      "SubSGD iter. 330/499: loss=73.0123049667693, w0=72.10000000000014, w1=14.24283654963142\n",
      "SubSGD iter. 331/499: loss=72.81073327027237, w0=72.80000000000014, w1=14.520963518433108\n",
      "SubSGD iter. 332/499: loss=73.55953102807874, w0=73.50000000000014, w1=14.899503301789839\n",
      "SubSGD iter. 333/499: loss=78.0929211516818, w0=72.80000000000014, w1=15.801135566202596\n",
      "SubSGD iter. 334/499: loss=74.24467282304012, w0=72.10000000000014, w1=14.60639672909817\n",
      "SubSGD iter. 335/499: loss=80.52226853392908, w0=71.40000000000013, w1=15.73232914259934\n",
      "SubSGD iter. 336/499: loss=83.98886079686872, w0=70.70000000000013, w1=16.012258135035804\n",
      "SubSGD iter. 337/499: loss=85.14971160302247, w0=71.40000000000013, w1=16.63139153098047\n",
      "SubSGD iter. 338/499: loss=87.21096542092639, w0=72.10000000000014, w1=17.254879653266645\n",
      "SubSGD iter. 339/499: loss=87.35814604614156, w0=72.80000000000014, w1=17.457316543307645\n",
      "SubSGD iter. 340/499: loss=89.21847024184282, w0=73.50000000000014, w1=17.835856326664377\n",
      "SubSGD iter. 341/499: loss=83.94625274754601, w0=74.20000000000014, w1=17.036025592601668\n",
      "SubSGD iter. 342/499: loss=80.71955961232382, w0=73.50000000000014, w1=16.44370763133349\n",
      "SubSGD iter. 343/499: loss=83.28859556010872, w0=72.80000000000014, w1=16.788884719058487\n",
      "SubSGD iter. 344/499: loss=82.46006110029425, w0=73.50000000000014, w1=16.756455711291128\n",
      "SubSGD iter. 345/499: loss=76.98045469244707, w0=72.80000000000014, w1=15.561716874186702\n",
      "SubSGD iter. 346/499: loss=79.3182310349094, w0=73.50000000000014, w1=16.178103823023953\n",
      "SubSGD iter. 347/499: loss=76.99165047709775, w0=72.80000000000014, w1=15.56418940964637\n",
      "SubSGD iter. 348/499: loss=79.80345606714162, w0=72.10000000000014, w1=15.920914928002208\n",
      "SubSGD iter. 349/499: loss=74.13989465427923, w0=72.80000000000014, w1=14.883400734188667\n",
      "SubSGD iter. 350/499: loss=71.30633007113869, w0=73.50000000000014, w1=14.264259578774285\n",
      "SubSGD iter. 351/499: loss=73.32773451634083, w0=74.20000000000014, w1=14.878920559904671\n",
      "SubSGD iter. 352/499: loss=76.25634349912767, w0=74.90000000000015, w1=15.502408682190849\n",
      "SubSGD iter. 353/499: loss=76.02616249875194, w0=74.20000000000014, w1=15.52637452199394\n",
      "SubSGD iter. 354/499: loss=75.80128193819147, w0=74.90000000000015, w1=15.399360076765914\n",
      "SubSGD iter. 355/499: loss=79.31725425499843, w0=74.20000000000014, w1=16.20747381780785\n",
      "SubSGD iter. 356/499: loss=81.32527131851505, w0=73.50000000000014, w1=16.55455780342784\n",
      "SubSGD iter. 357/499: loss=82.10174774365262, w0=74.20000000000014, w1=16.720364062995337\n",
      "SubSGD iter. 358/499: loss=86.3553451224855, w0=73.50000000000014, w1=17.40096324065142\n",
      "SubSGD iter. 359/499: loss=84.11814145641588, w0=74.20000000000014, w1=17.064600282975345\n",
      "SubSGD iter. 360/499: loss=87.71952634510743, w0=73.50000000000014, w1=17.611762585209217\n",
      "SubSGD iter. 361/499: loss=90.24222651798821, w0=72.80000000000014, w1=17.89169157764568\n",
      "SubSGD iter. 362/499: loss=84.68915390775726, w0=72.10000000000014, w1=16.83529034626679\n",
      "SubSGD iter. 363/499: loss=87.38303745130493, w0=71.40000000000013, w1=17.01715418984196\n",
      "SubSGD iter. 364/499: loss=86.07397041705997, w0=72.10000000000014, w1=17.06931453537167\n",
      "SubSGD iter. 365/499: loss=87.84941183702901, w0=71.40000000000013, w1=17.094612300760513\n",
      "SubSGD iter. 366/499: loss=81.16978135628128, w0=72.10000000000014, w1=16.192980036347755\n",
      "SubSGD iter. 367/499: loss=87.45408557170717, w0=71.40000000000013, w1=17.02901889362057\n",
      "SubSGD iter. 368/499: loss=82.49989022307531, w0=72.10000000000014, w1=16.44470635607468\n",
      "SubSGD iter. 369/499: loss=84.4402190660619, w0=72.80000000000014, w1=16.98566340804582\n",
      "SubSGD iter. 370/499: loss=87.70235719137611, w0=73.50000000000014, w1=17.609151530331996\n",
      "SubSGD iter. 371/499: loss=92.1698208030676, w0=72.80000000000014, w1=18.167275234081036\n",
      "SubSGD iter. 372/499: loss=92.52166615695106, w0=72.10000000000014, w1=18.056975200620244\n",
      "SubSGD iter. 373/499: loss=95.90748716580448, w0=72.80000000000014, w1=18.673362149457493\n",
      "SubSGD iter. 374/499: loss=94.39110774730955, w0=72.10000000000014, w1=18.318334671927666\n",
      "SubSGD iter. 375/499: loss=94.47739641280609, w0=72.80000000000014, w1=18.483787463860292\n",
      "SubSGD iter. 376/499: loss=99.74227977802003, w0=72.10000000000014, w1=19.019307146686497\n",
      "SubSGD iter. 377/499: loss=99.94454629653336, w0=72.80000000000014, w1=19.184759938619123\n",
      "SubSGD iter. 378/499: loss=104.51551909898713, w0=73.50000000000014, w1=19.801146887456373\n",
      "SubSGD iter. 379/499: loss=103.61040829245707, w0=72.80000000000014, w1=19.62279476607656\n",
      "SubSGD iter. 380/499: loss=99.51284836617558, w0=72.10000000000014, w1=18.99052033759487\n",
      "SubSGD iter. 381/499: loss=105.76189027383467, w0=72.80000000000014, w1=19.869768303491043\n",
      "SubSGD iter. 382/499: loss=110.15994882158691, w0=73.50000000000014, w1=20.422974219567156\n",
      "SubSGD iter. 383/499: loss=112.38188459366476, w0=74.20000000000014, w1=20.672572682254334\n",
      "SubSGD iter. 384/499: loss=118.20405927320067, w0=74.90000000000015, w1=21.225778598330447\n",
      "SubSGD iter. 385/499: loss=115.86072743844338, w0=74.20000000000014, w1=21.027017732511922\n",
      "SubSGD iter. 386/499: loss=118.18122622432472, w0=74.90000000000015, w1=21.223537815290424\n",
      "SubSGD iter. 387/499: loss=112.36029115922318, w0=74.20000000000014, w1=20.67033189921431\n",
      "SubSGD iter. 388/499: loss=116.70603779112335, w0=73.50000000000014, w1=21.09611804650505\n",
      "SubSGD iter. 389/499: loss=106.72224204970965, w0=72.80000000000014, w1=19.97780782589357\n",
      "SubSGD iter. 390/499: loss=101.50413977190641, w0=73.50000000000014, w1=19.450619187146344\n",
      "SubSGD iter. 391/499: loss=93.60828403051511, w0=74.20000000000014, w1=18.473821708204426\n",
      "SubSGD iter. 392/499: loss=87.95864671863436, w0=74.90000000000015, w1=17.619975437779157\n",
      "SubSGD iter. 393/499: loss=91.77988727980167, w0=75.60000000000015, w1=18.059899880663338\n",
      "SubSGD iter. 394/499: loss=90.39408667962613, w0=76.30000000000015, w1=17.663923637441506\n",
      "SubSGD iter. 395/499: loss=87.45310508389878, w0=75.60000000000015, w1=17.414325174754328\n",
      "SubSGD iter. 396/499: loss=91.93603770259082, w0=74.90000000000015, w1=18.198557902793652\n",
      "SubSGD iter. 397/499: loss=87.38849062117659, w0=75.60000000000015, w1=17.404188558302874\n",
      "SubSGD iter. 398/499: loss=79.80201115107201, w0=74.90000000000015, w1=16.235857757785404\n",
      "SubSGD iter. 399/499: loss=82.52300695609429, w0=74.20000000000014, w1=16.793981461534443\n",
      "SubSGD iter. 400/499: loss=82.87586044542499, w0=73.50000000000014, w1=16.828672320875913\n",
      "SubSGD iter. 401/499: loss=86.98297393537494, w0=72.80000000000014, w1=17.3986324454119\n",
      "SubSGD iter. 402/499: loss=84.02091248448406, w0=73.50000000000014, w1=17.02304660712533\n",
      "SubSGD iter. 403/499: loss=85.78311686440365, w0=72.80000000000014, w1=17.20720738544365\n",
      "SubSGD iter. 404/499: loss=89.36789702014079, w0=72.10000000000014, w1=17.592491525771777\n",
      "SubSGD iter. 405/499: loss=86.28752152543521, w0=71.40000000000013, w1=16.831134575152706\n",
      "SubSGD iter. 406/499: loss=91.28513263960158, w0=70.70000000000013, w1=17.30918277757883\n",
      "SubSGD iter. 407/499: loss=86.9437255143205, w0=71.40000000000013, w1=16.94326204684843\n",
      "SubSGD iter. 408/499: loss=79.30270119596238, w0=72.10000000000014, w1=15.81732963334726\n",
      "SubSGD iter. 409/499: loss=79.29224501960033, w0=72.80000000000014, w1=16.046451325634017\n",
      "SubSGD iter. 410/499: loss=75.21787934843813, w0=73.50000000000014, w1=15.307118526190074\n",
      "SubSGD iter. 411/499: loss=77.8887245919998, w0=74.20000000000014, w1=15.923505475027323\n",
      "SubSGD iter. 412/499: loss=77.3461975857314, w0=74.90000000000015, w1=15.740039695976904\n",
      "SubSGD iter. 413/499: loss=75.17851053446745, w0=75.60000000000015, w1=15.053345060470768\n",
      "SubSGD iter. 414/499: loss=70.23189588433551, w0=74.90000000000015, w1=13.84732877070032\n",
      "SubSGD iter. 415/499: loss=67.22975652539527, w0=74.20000000000014, w1=12.641312480929873\n",
      "SubSGD iter. 416/499: loss=69.4310526410273, w0=74.90000000000015, w1=13.546487584116937\n",
      "SubSGD iter. 417/499: loss=70.10736775690886, w0=74.20000000000014, w1=13.922073422403507\n",
      "SubSGD iter. 418/499: loss=67.76503386519215, w0=73.50000000000014, w1=12.864158115575949\n",
      "SubSGD iter. 419/499: loss=69.4231530366506, w0=72.80000000000014, w1=13.353841648972537\n",
      "SubSGD iter. 420/499: loss=72.1997299990033, w0=72.10000000000014, w1=13.978657748783483\n",
      "SubSGD iter. 421/499: loss=71.81630898188736, w0=72.80000000000014, w1=14.222970472492618\n",
      "SubSGD iter. 422/499: loss=73.83035084612168, w0=73.50000000000014, w1=14.968956126080014\n",
      "SubSGD iter. 423/499: loss=70.68332993987973, w0=74.20000000000014, w1=14.115109855654746\n",
      "SubSGD iter. 424/499: loss=72.91110494947768, w0=73.50000000000014, w1=14.727908026656158\n",
      "SubSGD iter. 425/499: loss=75.4275217339041, w0=74.20000000000014, w1=15.391052343699204\n",
      "SubSGD iter. 426/499: loss=72.6509454953797, w0=73.50000000000014, w1=14.656776600207404\n",
      "SubSGD iter. 427/499: loss=73.11275791773383, w0=74.20000000000014, w1=14.8225828597749\n",
      "SubSGD iter. 428/499: loss=73.8464235689054, w0=73.50000000000014, w1=14.973039536226029\n",
      "SubSGD iter. 429/499: loss=73.56677516662933, w0=74.20000000000014, w1=14.940610528458668\n",
      "SubSGD iter. 430/499: loss=77.58577464785171, w0=73.50000000000014, w1=15.829442352625161\n",
      "SubSGD iter. 431/499: loss=75.11323164498143, w0=72.80000000000014, w1=15.128508355190409\n",
      "SubSGD iter. 432/499: loss=78.31690535529124, w0=72.10000000000014, w1=15.606556557616532\n",
      "SubSGD iter. 433/499: loss=77.0996748544902, w0=72.80000000000014, w1=15.587977098717655\n",
      "SubSGD iter. 434/499: loss=75.1138522253985, w0=72.10000000000014, w1=14.841991445130258\n",
      "SubSGD iter. 435/499: loss=75.86656078274163, w0=72.80000000000014, w1=15.308573571096833\n",
      "SubSGD iter. 436/499: loss=82.44476016004678, w0=72.10000000000014, w1=16.434505984598005\n",
      "SubSGD iter. 437/499: loss=88.82276185766626, w0=71.40000000000013, w1=17.253164354403633\n",
      "SubSGD iter. 438/499: loss=91.21132944476201, w0=72.10000000000014, w1=17.86782533553402\n",
      "SubSGD iter. 439/499: loss=91.43974990158966, w0=72.80000000000014, w1=18.06416992905125\n",
      "SubSGD iter. 440/499: loss=83.51665906611044, w0=73.50000000000014, w1=16.938237515550078\n",
      "SubSGD iter. 441/499: loss=79.58687163520591, w0=72.80000000000014, w1=16.104899932990502\n",
      "SubSGD iter. 442/499: loss=75.99702662678148, w0=73.50000000000014, w1=15.48575877757612\n",
      "SubSGD iter. 443/499: loss=75.70075124824518, w0=74.20000000000014, w1=15.453329769808759\n",
      "SubSGD iter. 444/499: loss=73.55285280613619, w0=74.90000000000015, w1=14.849563699842246\n",
      "SubSGD iter. 445/499: loss=77.72984532158814, w0=75.60000000000015, w1=15.644733424959593\n",
      "SubSGD iter. 446/499: loss=79.95810943950876, w0=74.90000000000015, w1=16.265784998530187\n",
      "SubSGD iter. 447/499: loss=87.30403526092381, w0=75.60000000000015, w1=17.390914958660495\n",
      "SubSGD iter. 448/499: loss=87.2918720599493, w0=74.90000000000015, w1=17.51792940388852\n",
      "SubSGD iter. 449/499: loss=81.85467169441476, w0=74.20000000000014, w1=16.676739235663877\n",
      "SubSGD iter. 450/499: loss=79.26402361791448, w0=73.50000000000014, w1=16.167553391717625\n",
      "SubSGD iter. 451/499: loss=82.645737007044, w0=72.80000000000014, w1=16.676054509457458\n",
      "SubSGD iter. 452/499: loss=76.2855703161662, w0=73.50000000000014, w1=15.550122095956286\n",
      "SubSGD iter. 453/499: loss=76.83514452361591, w0=74.20000000000014, w1=15.703015853070868\n",
      "SubSGD iter. 454/499: loss=80.38063334396124, w0=74.90000000000015, w1=16.345945551834664\n",
      "SubSGD iter. 455/499: loss=80.1419464884836, w0=74.20000000000014, w1=16.36452501073354\n",
      "SubSGD iter. 456/499: loss=76.81241850928733, w0=74.90000000000015, w1=15.625192211289598\n",
      "SubSGD iter. 457/499: loss=77.17684209597637, w0=74.20000000000014, w1=15.775648887740726\n",
      "SubSGD iter. 458/499: loss=77.44955666590005, w0=73.50000000000014, w1=15.800946653129568\n",
      "SubSGD iter. 459/499: loss=80.24318896908039, w0=72.80000000000014, w1=16.23273923141299\n",
      "SubSGD iter. 460/499: loss=80.67345066611034, w0=73.50000000000014, w1=16.43517612145399\n",
      "SubSGD iter. 461/499: loss=80.2623031274494, w0=72.80000000000014, w1=16.236415255635464\n",
      "SubSGD iter. 462/499: loss=67.76341254764324, w0=73.50000000000014, w1=12.863271578045786\n",
      "SubSGD iter. 463/499: loss=71.03947503093207, w0=74.20000000000014, w1=14.228641030709397\n",
      "SubSGD iter. 464/499: loss=72.58930032709706, w0=73.50000000000014, w1=14.639716215251623\n",
      "SubSGD iter. 465/499: loss=73.97558083086787, w0=72.80000000000014, w1=14.840465752300874\n",
      "SubSGD iter. 466/499: loss=75.591399453565, w0=73.50000000000014, w1=15.393671668376987\n",
      "SubSGD iter. 467/499: loss=78.56264458101225, w0=72.80000000000014, w1=15.89868940020131\n",
      "SubSGD iter. 468/499: loss=81.10927985262097, w0=72.10000000000014, w1=16.181237219287535\n",
      "SubSGD iter. 469/499: loss=79.81045079829639, w0=72.80000000000014, w1=16.148808211520176\n",
      "SubSGD iter. 470/499: loss=82.4277565945557, w0=72.10000000000014, w1=16.431356030606402\n",
      "SubSGD iter. 471/499: loss=80.7591787726731, w0=72.80000000000014, w1=16.331078931366193\n",
      "SubSGD iter. 472/499: loss=85.99129016040061, w0=73.50000000000014, w1=17.343517269232613\n",
      "SubSGD iter. 473/499: loss=80.15364626030112, w0=74.20000000000014, w1=16.366719790290695\n",
      "SubSGD iter. 474/499: loss=77.14003211081503, w0=73.50000000000014, w1=15.735554450295842\n",
      "SubSGD iter. 475/499: loss=66.82061698989268, w0=74.20000000000014, w1=12.362410772706165\n",
      "SubSGD iter. 476/499: loss=68.32167299524536, w0=73.50000000000014, w1=13.146643500745489\n",
      "SubSGD iter. 477/499: loss=69.96309643138336, w0=74.20000000000014, w1=13.871663690826292\n",
      "SubSGD iter. 478/499: loss=71.80340613746236, w0=73.50000000000014, w1=14.41468015219139\n",
      "SubSGD iter. 479/499: loss=74.88173316840656, w0=72.80000000000014, w1=15.071561119944354\n",
      "SubSGD iter. 480/499: loss=77.48975852673824, w0=72.10000000000014, w1=15.421898053312745\n",
      "SubSGD iter. 481/499: loss=77.92423197592515, w0=72.80000000000014, w1=15.765610674496136\n",
      "SubSGD iter. 482/499: loss=79.39561513999809, w0=73.50000000000014, w1=16.193127759713555\n",
      "SubSGD iter. 483/499: loss=78.5960472868447, w0=74.20000000000014, w1=16.06611331448553\n",
      "SubSGD iter. 484/499: loss=77.75049751668725, w0=73.50000000000014, w1=15.863676424444531\n",
      "SubSGD iter. 485/499: loss=83.15321723615537, w0=72.80000000000014, w1=16.76530868885729\n",
      "SubSGD iter. 486/499: loss=83.27955461251133, w0=72.10000000000014, w1=16.586956567477475\n",
      "SubSGD iter. 487/499: loss=80.0414049941204, w0=71.40000000000013, w1=15.628821476575668\n",
      "SubSGD iter. 488/499: loss=78.25214507117859, w0=70.70000000000013, w1=14.681909214833238\n",
      "SubSGD iter. 489/499: loss=76.29494230069727, w0=71.40000000000013, w1=14.72423577143673\n",
      "SubSGD iter. 490/499: loss=75.0030049393442, w0=72.10000000000014, w1=14.812763284925856\n",
      "SubSGD iter. 491/499: loss=79.96084384742812, w0=72.80000000000014, w1=16.17813273758947\n",
      "SubSGD iter. 492/499: loss=88.42518269545747, w0=73.50000000000014, w1=17.718195075976656\n",
      "SubSGD iter. 493/499: loss=90.97767640824128, w0=72.80000000000014, w1=17.99812406841312\n",
      "SubSGD iter. 494/499: loss=86.63035507559675, w0=73.50000000000014, w1=17.44401699441654\n",
      "SubSGD iter. 495/499: loss=90.53115572530359, w0=72.80000000000014, w1=17.933700527813127\n",
      "SubSGD iter. 496/499: loss=86.49404586787293, w0=72.10000000000014, w1=17.13853080269578\n",
      "SubSGD iter. 497/499: loss=87.04689591366133, w0=72.80000000000014, w1=17.40866925298545\n",
      "SubSGD iter. 498/499: loss=80.32976827172135, w0=73.50000000000014, w1=16.37115505917191\n",
      "SubSGD iter. 499/499: loss=82.30419754652277, w0=72.80000000000014, w1=16.615181883881064\n",
      "SubSGD: execution time=0.062 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ac5eb93363458d99c2aa7edb9fad08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
